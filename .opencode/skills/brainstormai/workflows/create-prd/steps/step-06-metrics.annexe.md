---
type: annexe
step: "06"
name: metrics
parent: step-06-metrics.md
title: Annexe â€” MÃ©triques et Jalons
version: 2.0
---

# Annexe Step 06 â€” MÃ©triques et Jalons

RÃ©fÃ©rence dÃ©taillÃ©e pour les procÃ©dures, templates, challenge Rex et scÃ©narios d'erreur de l'Ã©tape P06. ComplÃ¨te `step-06-metrics.md`.

---

## P06.A1 â€” ProcÃ©dure P06.2 : KPIs contextuels

### Framework AARRR (Pirate Metrics)

Le framework AARRR structure les mÃ©triques selon le parcours utilisateur :

| Ã‰tape | Question clÃ© | Tu la mesures si... |
|---|---|---|
| **A**cquisition | Comment les gens te trouvent ? | Objectif visibilitÃ© ou croissance |
| **A**ctivation | Vivent-ils le "moment aha" ? | Objectif onboarding ou premiÃ¨re valeur |
| **R**Ã©tention | Est-ce qu'ils reviennent ? | Objectif fidÃ©lisation |
| **R**evenue | Est-ce qu'ils paient ? | Objectif monÃ©tisation |
| **R**ecommandation | Est-ce qu'ils en parlent ? | Objectif croissance organique |

### Catalogue de KPIs par catÃ©gorie

#### Acquisition

| KPI | Ce qu'il mesure | Comment le collecter | Cibles typiques |
|---|---|---|---|
| **CAC** | CoÃ»t pour attirer 1 utilisateur | Budget marketing Ã· nouveaux inscrits | < 10â‚¬ B2C, < 100â‚¬ B2B |
| **Taux d'inscription** | % visiteurs â†’ comptes crÃ©Ã©s | Inscrits Ã· visiteurs Ã— 100 | 2-5% landing, 10-20% rÃ©fÃ©rÃ© |
| **Sources de trafic** | D'oÃ¹ viennent tes utilisateurs | Analytics (UTM, referrer) | DiversifiÃ© > 3 sources |

#### Activation

| KPI | Ce qu'il mesure | Comment le collecter | Cibles typiques |
|---|---|---|---|
| **ComplÃ©tion onboarding** | % d'inscrits qui finissent le parcours | Ã‰vÃ©nement "onboarding_complete" Ã· inscrits | > 60% |
| **Time-to-value** | Temps avant la premiÃ¨re valeur obtenue | DÃ©lai inscription â†’ action clÃ© | < 5 min B2C, < 1 jour B2B |
| **PremiÃ¨re action clÃ©** | % qui rÃ©alisent l'action core | Ã‰vÃ©nement spÃ©cifique (premier match, etc.) | > 40% en 24h |

#### RÃ©tention

| KPI | Ce qu'il mesure | Comment le collecter | Cibles typiques |
|---|---|---|---|
| **DAU/MAU** | FrÃ©quence d'usage quotidien | Actifs jour Ã· actifs mois | > 20% bon, > 50% exceptionnel |
| **Taux de churn** | % d'utilisateurs perdus par mois | Perdus Ã· total par mois | < 5% B2B, < 8% B2C |
| **RÃ©tention cohorte** | % encore actifs aprÃ¨s N jours | Actifs J7/J30 Ã· cohorte | J7 > 30%, J30 > 15% |

#### Engagement

| KPI | Ce qu'il mesure | Comment le collecter | Cibles typiques |
|---|---|---|---|
| **DurÃ©e de session** | Temps passÃ© par visite | Analytics (start â†’ end) | 2 min outil, 20 min contenu |
| **Features utilisÃ©es** | FonctionnalitÃ©s par session | Compteur Ã©vÃ©nements | > 3 par session |
| **FrÃ©quence de retour** | Sessions par utilisateur par semaine | Sessions Ã· actifs | > 3/semaine |

#### Revenue

| KPI | Ce qu'il mesure | Comment le collecter | Cibles typiques |
|---|---|---|---|
| **MRR** | Revenus mensuels rÃ©currents | Somme abonnements actifs | Croissance > 10% mois/mois |
| **ARPU** | Revenu moyen par utilisateur | MRR Ã· payants | DÃ©pend du marchÃ© |
| **Taux de conversion** | % gratuits â†’ payants | Payants Ã· inscrits Ã— 100 | 2-5% freemium, > 10% trial |
| **LTV** | Valeur totale d'un client | ARPU Ã— durÃ©e moyenne | LTV > 3Ã— CAC |

#### Satisfaction

| KPI | Ce qu'il mesure | Comment le collecter | Cibles typiques |
|---|---|---|---|
| **NPS** | ProbabilitÃ© de recommandation | Survey in-app (0-10) / 90 jours | > 30 bon, > 50 excellent |
| **CSAT** | Satisfaction ponctuelle | Survey post-action (1-5) | > 4.0/5 |
| **Tickets support** | Volume de demandes d'aide | Helpdesk / compteur | < 5% des actifs |

---

## P06.A2 â€” ProcÃ©dure P06.3 : Cadre SMART appliquÃ© aux KPIs

### Template SMART par KPI

```markdown
### KPI : {{NOM_KPI}}
| CritÃ¨re | Valeur |
|---|---|
| **SpÃ©cifique** | Mesurer {{QUOI}} pour {{OBJECTIF}} |
| **Mesurable** | Via {{OUTIL}} â€” formule : {{CALCUL}} |
| **Atteignable** | Baseline : {{ACTUEL}} â†’ Cible : {{CIBLE}} |
| **RÃ©aliste** | {{CONTRAINTES}} Â· Benchmark : {{COMPARABLE}} |
| **Temporel** | Deadline : {{DATE}} Â· Suivi : {{FRÃ‰QUENCE}} |
```

### Bons vs mauvais exemples

| CritÃ¨re | âŒ Mauvais | âœ… Bon |
|---|---|---|
| SpÃ©cifique | Â« Augmenter le trafic Â» | Â« 5 000 visiteurs uniques / mois Â» |
| Mesurable | Â« Les gens sont satisfaits Â» | Â« NPS > 40 via survey in-app trimestrielle Â» |
| Atteignable | Â« 1M utilisateurs en 1 mois Â» | Â« 500 inscrits en 3 mois (2 devs, 0 budget) Â» |
| RÃ©aliste | Â« Churn 0% Â» | Â« Churn < 5% (benchmark SaaS B2B : 3-7%) Â» |
| Temporel | Â« Un jour Â» | Â« D'ici le 30 juin 2027, suivi mensuel Â» |

### Erreurs courantes

| Erreur | Correction |
|---|---|
| Pas de baseline (50% de quoi ?) | Ã‰tablir la valeur actuelle (ou 0 si nouveau) |
| Cible copier-coller pour tous les KPIs | Adapter au contexte (scope, ressources, marchÃ©) |
| FrÃ©quence absente | DÃ©finir : quotidien, hebdo, mensuel |
| Outil non identifiÃ© | Nommer : GA, Mixpanel, Stripe, survey in-app |
| Deadline floue (Â« Ã  moyen terme Â») | Date prÃ©cise ou relative (L+30, L+90) |

---

## P06.A3 â€” ProcÃ©dure P06.4 : Jalons par scope

### Scope MVP â€” 3 jalons

| Jalon | DurÃ©e typique | Livrables | CritÃ¨res de passage |
|---|---|---|---|
| **Alpha** | L-8 Ã  L-4 sem. | Features Must fonctionnelles, tests internes | 0 bug critique, 100% Must couverts |
| **BÃªta** | L-4 Ã  L-1 sem. | Correction bugs, onboarding, 5-20 testeurs | ComplÃ©tion onboarding > 50%, 0 bloquant |
| **Lancement** | L | Produit live, monitoring, support | Uptime > 99%, KPIs d'acquisition actifs |

### Scope Growth â€” + 2 jalons

| Jalon | Date | Livrables | CritÃ¨res de passage |
|---|---|---|---|
| **Revue 1 mois** | L+30j | Quick fixes, ajustements onboarding | Tendance acquisition positive |
| **Revue 3 mois** | L+90j | Features Should prioritaires, itÃ©rations | RÃ©tention J30 mesurÃ©e, go/no-go |

### Scope Vision â€” + 2 jalons

| Jalon | Date | Livrables | CritÃ¨res de passage |
|---|---|---|---|
| **Revue 6 mois** | L+180j | Features Could, A/B tests | LTV/CAC > 3, scalabilitÃ© validÃ©e |
| **Planning V2** | L+12 mois | Bilan complet, roadmap V2 | KPIs cibles atteints ou expliquÃ©s |

### Template jalon

```markdown
### Jalon : {{NOM}}
- **Date cible** : {{DATE}}
- **Livrables** : {{LIVRABLE_1}}, {{LIVRABLE_2}}
- **KPIs de passage** : {{KPI_1}} â‰¥ {{SEUIL}}, {{KPI_2}} â‰¥ {{SEUIL}}
- **DÃ©pendances** : {{JALON_PRÃ‰CÃ‰DENT}}
```

---

## P06.A4 â€” ProcÃ©dure P06.5 : Rex Challenge MÃ©triques

### 5 questions de challenge

Rex pose 2 Ã  4 de ces questions (jamais les 5 d'un coup) :

| # | Question | Ce que Ã§a teste | Si faible |
|---|---|---|---|
| 1 | Â« Comment tu mesures "{{KPI}}" concrÃ¨tement ? Tu as l'outil ? Â» | FaisabilitÃ© | John propose un outil gratuit (GA, Mixpanel free, Stripe) |
| 2 | Â« Ton objectif de {{CIBLE}} en {{DURÃ‰E}} â€” d'oÃ¹ Ã§a sort ? Â» | RÃ©alisme | John cherche un benchmark comparable |
| 3 | Â« Un seul KPI pour juger du succÃ¨s : lequel ? Â» | North star | Si hÃ©sitation â†’ pas de north star, John aide |
| 4 | Â« {{KPI}} = gros chiffre, mais quel impact concret ? Â» | Vanity metric | Remplacer ou dÃ©prioriser |
| 5 | Â« {{N}} jalons en {{DURÃ‰E}}. Lequel tu sacrifies en premier ? Â» | Priorisation | Jalons mal hiÃ©rarchisÃ©s â†’ revoir |

### DÃ©tection des vanity metrics

| Signal | Vanity metric | Alternative actionnable |
|---|---|---|
| Gros chiffre total | Â« 10 000 inscrits ! Â» | Inscrits actifs cette semaine (DAU) |
| Pas de contexte | Â« 500 tÃ©lÃ©chargements Â» | Funnel : tÃ©lÃ©chargements â†’ inscriptions â†’ activation |
| Non actionnable | Â« 2 000 pages vues Â» | Taux de rebond, conversion |
| Pas de tendance | Â« 100 utilisateurs Â» | Croissance semaine/semaine (+12%) |

> **[Rex]** Â« Si demain tu doubles "{{KPI}}", qu'est-ce qui change pour ton produit ? Rien ? C'est du bruit, pas du signal. Â»

### Technique "Et si tu mesurais l'inverse ?"

| KPI proposÃ© | Inverse | Ce que Ã§a rÃ©vÃ¨le |
|---|---|---|
| Taux d'inscription | Taux d'abandon formulaire | OÃ¹ tu perds les gens |
| DurÃ©e de session | Taux de sortie < 30 sec | Si le produit accroche |
| NPS positif | DÃ©tracteurs (0-6) | GravitÃ© des insatisfactions |
| Features utilisÃ©es | Features jamais utilisÃ©es | Code mort Ã  Ã©liminer |

### North Star Metric

La north star est le **seul KPI** qui capture la valeur fondamentale de ton produit.

| Type de produit | North star typique | Pourquoi |
|---|---|---|
| Marketplace | Transactions complÃ©tÃ©es | Valeur acheteur + vendeur |
| SaaS productivitÃ© | Actions core / utilisateur / semaine | Usage = rÃ©tention |
| RÃ©seau social | DAU avec interaction | Engagement = croissance |
| E-commerce | Commandes livrÃ©es | Promesse tenue |
| Contenu | Temps de lecture/visionnage | Valeur perÃ§ue |

**Test** : 1) Â« La seule chose que ton produit doit rÃ©ussir ? Â» 2) Â« Si ce chiffre monte, ton produit va bien ? Â» 3) Â« Ton Ã©quipe comprend ce KPI ? Â» â€” Si oui aux 3 â†’ c'est ta north star.

---

## P06.A5 â€” ScÃ©narios d'erreur et rÃ©cupÃ©ration

| ID | ScÃ©nario | RÃ©cupÃ©ration |
|---|---|---|
| E06.1 | Objectifs P02 oubliÃ©s ou incohÃ©rents | Revenir Ã  P02, mettre Ã  jour, reprendre P06 |
| E06.2 | L'utilisateur ne sait pas choisir de KPIs | John propose 2-3 KPIs prÃ©-sÃ©lectionnÃ©s : Â« Je te recommande ceux-lÃ . Â» |
| E06.3 | Trop de KPIs (> 3 par objectif) | Rex : Â« Si tu mesures tout, tu ne mesures rien. Garde les 2 qui comptent. Â» |
| E06.4 | Cibles irrÃ©alistes | John propose un benchmark : Â« En {{DOMAINE}}, la cible typique est {{RANGE}}. Â» |
| E06.5 | Timeline incohÃ©rente avec le scope | John recadre le nombre de jalons selon le scope |
| E06.6 | Session interrompue | Reprendre au dernier checkpoint validÃ© |

---

## P06.A6 â€” Exemple complet : Parcours P06 pour SportMate

**Contexte** : App mobile matching sportif en zone rurale Â· Scope MVP Â· 3 objectifs (Acquisition 200 actifs, Engagement 3 sessions/sem, Satisfaction NPS > 40)

**P06.1** â€” John rappelle les 3 objectifs, l'utilisateur confirme.

**P06.2** â€” KPIs contextuels :

> **[John]** Â« OBJ-01 Acquisition locale â€” KPIs : inscriptions par canton + taux d'activation. Â»
> **Utilisateur** : Â« Les deux, c'est complÃ©mentaire. Â»

**P06.3** â€” SMART : Inscriptions/canton â†’ SpÃ©cifique (3 cantons), Mesurable (Firebase), Atteignable (0â†’50), RÃ©aliste (flyers mairie), Temporel (L+90j). AjustÃ© Ã  50/canton (stretch: 67).

**P06.4** â€” 3 jalons : Alpha (L-6 sem) â†’ BÃªta (L-2 sem) â†’ Lancement.

**P06.5** â€” Rex : Â« 150 inscrits sans budget â€” comment ? 1 seul KPI ? Â» â†’ Utilisateur choisit taux d'activation = north star.

**P06.6** â€” Validation :

> | KPI | Objectif | Baseline | Cible | Mesure | Deadline |
> |---|---|---|---|---|---|
> | Inscriptions/canton | OBJ-01 | 0 | 50 (stretch: 67) | Firebase + gÃ©oloc | L+90j |
> | Taux d'activation | OBJ-01 | 0% | > 40% | Ã‰vÃ©nement "first_match" | L+30j |
> | Sessions/semaine | OBJ-02 | 0 | 3 | Firebase Analytics | L+90j |
> | NPS | OBJ-03 | â€” | > 40 | Survey in-app trimestrielle | L+180j |
>
> **North Star** : Taux d'activation (premier match rÃ©alisÃ©)

---

## P06.A7 â€” Gardes comportementaux

### John (PM)

| Garde | Comportement |
|---|---|
| Contextuel | Relie chaque KPI Ã  un objectif de P02 |
| Progressif | Un objectif Ã  la fois |
| PÃ©dagogue | Explique le *pourquoi*, pas juste le *quoi* |
| Pragmatique | Outils de mesure concrets et accessibles |
| Anti-mur-de-texte | Max 8 lignes sans interaction |

### Rex (Challenger)

| Garde | Comportement |
|---|---|
| IntensitÃ© ğŸŸ¡ | ModÃ©rÃ©e â€” directe mais constructive |
| Timing | AprÃ¨s P06.4, quand KPIs + jalons sont posÃ©s |
| Focus | MesurabilitÃ©, rÃ©alisme, vanity metrics, north star |
| Limite | 3-5 challenges, 2 allers-retours par point |
| Blocage interdit | Accepter la dÃ©cision de l'utilisateur, noter le risque |

---

## P06.A8 â€” Risques spÃ©cifiques Ã  P06

| ID | Risque | ProbabilitÃ© | Impact | Mitigation |
|----|--------|-------------|--------|------------|
| RP06-01 | Vanity metrics â€” KPIs impressionnants mais non actionnables | Haute | Haut | Appliquer le test Rex : Â« Si tu doubles ce chiffre, qu'est-ce qui change ? Â» Remplacer par un KPI actionnable. |
| RP06-02 | KPIs non mesurables â€” pas d'outil ni de mÃ©thode de collecte identifiÃ©s | Moyenne | Haut | Exiger un outil concret et une formule de calcul pour chaque KPI dÃ¨s P06.3. Pas d'outil = pas de KPI. |
| RP06-03 | Baselines absentes â€” cibles dÃ©finies sans point de rÃ©fÃ©rence | Haute | Moyen | Ã‰tablir la valeur actuelle (ou 0 si produit nouveau) pour chaque KPI. Cible sans baseline = cible arbitraire. |
| RP06-04 | MÃ©triques non alignÃ©es avec les objectifs â€” KPIs dÃ©connectÃ©s de P02 | Moyenne | Haut | VÃ©rifier que chaque KPI est reliÃ© Ã  un objectif de P02. KPI orphelin = KPI Ã  supprimer ou objectif manquant. |
| RP06-05 | Jalons irrÃ©alistes â€” timeline incohÃ©rente avec les ressources et le scope | Moyenne | Moyen | Calibrer le nombre de jalons selon le scope (MVP = 3, Growth = +2, Vision = +2). VÃ©rifier la faisabilitÃ© avec l'utilisateur. |

---

## P06.A9 â€” Portes qualitÃ© P06

| Niveau | CritÃ¨res |
|--------|----------|
| **Minimum** | Chaque objectif P02 a au moins 1 KPI associÃ© Â· Chaque KPI a un outil de mesure identifiÃ© Â· Baselines dÃ©finies (valeur actuelle ou 0) Â· Jalons dÃ©finis selon le scope |
| **Standard** | Tous les critÃ¨res Minimum + Chaque KPI passe le cadre SMART complet Â· Cibles rÃ©alistes avec benchmark ou justification Â· North star metric identifiÃ©e Â· Plan de monitoring dÃ©fini (frÃ©quence + responsable) Â· Rex challenge effectuÃ© (2-4 questions) |
| **Excellence** | Tous les critÃ¨res Standard + ZÃ©ro vanity metric dÃ©tectÃ©e Â· Chaque KPI a une cible standard et une cible stretch Â· MÃ©triques leading et lagging Ã©quilibrÃ©es Â· Alignement vision â†” objectifs â†” KPIs â†” jalons vÃ©rifiÃ© bout en bout Â· Dashboard ou tableau de bord esquissÃ© |

---

## P06.A10 â€” Anti-patterns P06

| Anti-pattern | Description | ConsÃ©quence | RemÃ¨de |
|---|---|---|---|
| Trop de mÃ©triques | Mesurer 10+ KPIs â€” Â« dashboard de NoÃ«l Â» | Perte de focus, paralysie analytique, aucun KPI suivi sÃ©rieusement | Limiter Ã  2-3 KPIs par objectif. Rex challenge : Â« Lequel tu sacrifies en premier ? Â» |
| Pas de propriÃ©taire | KPIs dÃ©finis mais personne n'est responsable du suivi | MÃ©triques jamais consultÃ©es, aucune action corrective | Attribuer un propriÃ©taire et une frÃ©quence de revue Ã  chaque KPI |
| Indicateurs retardÃ©s uniquement | Que des lagging indicators (chiffre d'affaires, churn) sans leading indicators (activation, engagement) | RÃ©action trop tardive, pas de signal d'alerte prÃ©coce | Ã‰quilibrer avec des indicateurs avancÃ©s : complÃ©tion onboarding, frÃ©quence d'usage, NPS |
| Potentiel de gaming | KPIs qui incitent Ã  des comportements pervers (ex. : Â« nombre d'inscrits Â» sans activation) | Optimisation du chiffre au dÃ©triment de la valeur rÃ©elle | Coupler chaque KPI avec un Â« garde-fou Â» : inscrits + taux d'activation, sessions + durÃ©e utile |
| DÃ©connexion de la valeur utilisateur | MÃ©triques purement business sans indicateur de satisfaction ou d'usage rÃ©el | Produit rentable Ã  court terme mais sans rÃ©tention | Inclure au moins 1 KPI centrÃ© utilisateur (NPS, CSAT, rÃ©tention cohorte) par objectif |
